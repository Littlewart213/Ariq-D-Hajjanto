import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import time

# Check whether PyTorch is installed
torch.__version__

# Set up the transforms
transform = transforms.ToTensor()

# input MNIST dataset
train_data = datasets.MNIST(root='/CNN/Data', train=True, download=True, transform=transform)
test_data = datasets.MNIST(root='/CNN/Data', train=False, download=True, transform=transform)

# sidebar untuk input
dataset = st.sidebar.text_input("Dataset:", value="MNIST")
model_name = st.sidebar.text_input("Model Name:", value="model-mnist")

# main function
def main():
    st.title("FP Multimodal Biomedical Image Analysis (Ariq D. Hajjanto/5023201057)")
    menu = ["Home", "Dataset", "Artificial Neural Network"]
    choice = st.sidebar.selectbox("Menu", menu)

    if choice == "Home":
        st.subheader("Home")
    elif choice == "Artificial Neural Network":
        st.subheader("ANN")

    traindata = int(st.sidebar.number_input("Training Data Number:", min_value=1, max_value=600))
    image, label = train_data[traindata]
    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 4))
    ax.imshow(train_data[traindata][0].reshape((28, 28)), cmap="gray")
    ax.set_title('Train Data')
    st.pyplot(fig)

    st.write(f'Shape: {image.shape}')
    st.write(f'Label: {label}')

    torch.manual_seed(101)
    train_batch_size = int(st.sidebar.number_input("Train Batch Size:", min_value=1, max_value=600))
    test_batch_size = int(st.sidebar.number_input("Test Batch Size:", min_value=1, max_value=600))
    epochs = st.sidebar.slider('Enter Epoch Value', 0, 20, 1)
    learning_rate = st.sidebar.number_input("Learning Rate:", value=0.001)

    stop_training = False

    if st.sidebar.button("Start"):
        train_loader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)
        test_loader = DataLoader(test_data, batch_size=test_batch_size, shuffle=False)
        model = train_model(train_loader, test_loader, epochs, train_batch_size, test_batch_size, learning_rate, stop_training)

        # Show confusion matrix
        show_confusion_matrix(test_loader, model)

    if st.sidebar.button("Stop"):
        stop_training = True
        st.write("Training will stop at the end of the current epoch.")

# Function to define the model architecture
class MultilayerPerceptron(nn.Module):
    def __init__(self, in_sz=784, out_sz=10, layers=[120, 84]):
        super().__init__()
        self.fc1 = nn.Linear(in_sz, layers[0])
        self.fc2 = nn.Linear(layers[0], layers[1])
        self.fc3 = nn.Linear(layers[1], out_sz)

    def forward(self, X):
        X = F.relu(self.fc1(X))
        X = F.relu(self.fc2(X))
        X = self.fc3(X)
        return F.log_softmax(X, dim=1)

def train_model(train_loader, test_loader, epochs, train_batch_size, test_batch_size, learning_rate, stop_training):
    # Inisalisasi
    model = MultilayerPerceptron()

    # Set up the optimizer and criterion
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    # Track the training and testing losses
    train_losses = []
    test_losses = []

    # Track the training and testing accuracies
    train_correct = []
    test_correct = []

    # Check if a GPU is available
    train_on_gpu = torch.cuda.is_available()
    if train_on_gpu:
        model.cuda()

    start_time = time.time()

    # Create an empty placeholder for displaying progress
    progress_placeholder = st.empty()

    iteration = 0
    for epoch in range(epochs):
        if stop_training:
            break

        # Set the model to train mode
        model.train()
        trn_corr = 0
        tst_corr = 0

        for batch, (X_train, y_train) in enumerate(train_loader):
            if train_on_gpu:
                X_train, y_train = X_train.cuda(), y_train.cuda()

            # Flatten the image tensors
            X_train = X_train.view(X_train.shape[0], -1)

            optimizer.zero_grad()
            output = model(X_train)
            loss = criterion(output, y_train)
            loss.backward()
            optimizer.step()

            # Track the training loss and accuracy for each iteration
            predicted = torch.max(output.data, 1)[1]
            batch_corr = (predicted == y_train).sum()
            trn_corr += batch_corr

            # Append the losses and accuracies for each iteration
            train_losses.append(loss.item())
            train_correct.append(batch_corr.item() / train_batch_size)
            iteration += 1

            # Update the progress display
            progress_placeholder.text(f"Epoch: {epoch+1}/{epochs}, Batch: {batch+1}/{len(train_loader)}, Loss: {loss.item():.6f}, Accuracy: {batch_corr.item() / train_batch_size:.4f}")

        # Set the model to evaluation mode
        model.eval()

        with torch.no_grad():
            for batch, (X_test, y_test) in enumerate(test_loader):
                if train_on_gpu:
                    X_test, y_test = X_test.cuda(), y_test.cuda()

                # Flatten the image tensors
                X_test = X_test.view(X_test.shape[0], -1)

                # Make predictions
                y_val = model(X_test)

                # Calculate the loss
                loss = criterion(y_val, y_test)

                # Track the testing loss and accuracy for each iteration
                predicted = torch.max(y_val.data, 1)[1]
                tst_corr += (predicted == y_test).sum()

                # Append the losses and accuracies for each iteration
                test_losses.append(loss.item())
                test_correct.append((predicted == y_test).sum().item() / test_batch_size)

        if stop_training:
            break

    st.write(f'\nDuration: {time.time() - start_time:.0f} seconds')
    st.write("Training completed!")

    # Plot the loss and accuracy for each iteration
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='Training Loss')
    plt.plot(train_correct, label='Training Accuracy')
    plt.xlabel('Iteration')
    plt.ylabel('Value')
    plt.title('Training Loss and Accuracy')
    plt.legend()
    st.pyplot(plt)

    return model

def show_confusion_matrix(test_loader, model):
    # Set the model to evaluation mode
    model.eval()

    # Check if a GPU is available
    train_on_gpu = torch.cuda.is_available()
    if train_on_gpu:
        model.cuda()

    # Create empty lists to store the true labels and predicted labels
    true_labels = []
    predicted_labels = []

    with torch.no_grad():
        for batch, (X_test, y_test) in enumerate(test_loader):
            if train_on_gpu:
                X_test, y_test = X_test.cuda(), y_test.cuda()

            # Flatten the image tensors
            X_test = X_test.view(X_test.shape[0], -1)

            # Make predictions
            y_val = model(X_test)

            # Get the predicted labels
            predicted = torch.max(y_val.data, 1)[1]

            # Append the true labels and predicted labels to the lists
            true_labels.extend(y_test.cpu().numpy())
            predicted_labels.extend(predicted.cpu().numpy())

    # Calculate the confusion matrix
    cm = confusion_matrix(true_labels, predicted_labels)

    # Plot the confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    st.pyplot(plt)

if __name__ == '__main__':
    main()
